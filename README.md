# DidYouEvenCode?

> An AI that actually checks your code - not vibes or intentions.

[![Hackathon](https://img.shields.io/badge/Hackathon-Group%20190-blue)](https://github.com/yourusername/assignment-evaluator)

---

## âœ¨ Features

- ðŸš€ **Fast Evaluation** - Results in 5-15 seconds (GPU) or 10-20 seconds (CPU)
- ðŸ” **Semantic Code Search** - Uses MiniLM embeddings + FAISS vector similarity
- ðŸ“Š **Detailed Feedback** - PASS/PARTIAL/FAIL per requirement with evidence quotes
- ðŸ¤– **AI Summary** - Natural language evaluation report via Flan-T5
- ðŸ“ˆ **Confidence Scores** - Shows reliability of each evaluation
- ðŸ’¾ **Downloadable Reports** - JSON format with complete analysis
- âš¡ **Parallel Processing** - Evaluates all requirements simultaneously

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Three-Tier System                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend    â”‚  â† File upload UI, results dashboard
â”‚   (localhost:5173)  â”‚     Dark theme, drag-and-drop
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP/REST
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node.js Backend   â”‚  â† MVC architecture, orchestration
â”‚   (localhost:5051)  â”‚     Express, file handling, pipeline
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP/REST
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python ML Service  â”‚  â† Embeddings, search, AI summary
â”‚   (Google Colab)    â”‚     MiniLM, FAISS, Flan-T5
â”‚  Cloudflare Tunnel  â”‚     GPU-accelerated when available
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

**Frontend:**
- React 18 + Vite
- Axios for API calls
- CSS3 (dark theme with gradients)

**Backend:**
- Node.js + Express
- MVC pattern (Controllers â†’ Services â†’ Utils)
- Multer for file uploads
- Environment-based configuration

**ML Service:**
- Python 3 + Flask
- Transformers (MiniLM, Flan-T5)
- FAISS (Facebook AI Similarity Search)
- PyTorch (GPU/CPU compatible)
- Cloudflare Tunnel for public access

---

## ðŸ“‹ Prerequisites

- **Node.js** 16+ and npm
- **Google Account** (for Colab - free tier works)
- **Test files**: Jupyter notebook (`.ipynb`) and assignment text (`.txt` or `.md`)

---

## ðŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/aashapovalov/assignment-evaluator-copilot
cd assignment-evaluator
```

### 2. Environment Setup

**Backend:**
```bash
cd backend
cp .env.example .env
nano .env  # Update ML_SERVICE_URL after starting Colab
```

**Frontend:**
```bash
cd frontend
cp .env.example .env
# Default settings usually work - edit if needed
```

### 3. Start ML Service (Google Colab)

1. **Open notebook:** [Open in Colab](https://colab.research.google.com/drive/YOUR_NOTEBOOK_ID)

2. **Enable GPU (optional but recommended):**
    - Runtime â†’ Change runtime type â†’ GPU (T4) â†’ Save

3. **Run all cells:**
    - Runtime â†’ Run all
    - Wait ~2 minutes for models to load

4. **Copy Cloudflare URL:**
   ```
   ðŸš€ ML SERVICE IS LIVE!
   ðŸ“¡ URL: https://your-random-url.trycloudflare.com
   ```

5. **Update backend config:**
   ```bash
   # In backend/.env
   ML_SERVICE_URL=https://your-random-url.trycloudflare.com
   ```

### 4. Install Dependencies

```bash
# Backend
cd backend
npm install

# Frontend  
cd ../frontend
npm install
```

### 5. Run the Application

**Terminal 1 - Backend:**
```bash
cd backend
npm start

# Output:
# ðŸš€ Server running on port 5051
# ðŸ“¡ ML Service: https://your-url.trycloudflare.com
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev

# Output:
# âžœ Local: http://localhost:5173
```

### 6. Test the System

1. **Open browser:** `http://localhost:5173`

2. **Upload test files:**
    - Assignment: `data/test_assignment.txt`
    - Notebook: `data/test_notebook.ipynb`

3. **Click "Evaluate my suffering"**

4. **View results** (should show ~90% score with detailed breakdown)

---

## ðŸ§ª Testing

### Via cURL

```bash
# Full evaluation
curl -X POST http://localhost:5051/api/evaluate \
  -F "assignment=@data/test_assignment.txt" \
  -F "notebook=@data/test_notebook.ipynb" \
  | jq '.'

# Check breakdown only
curl -X POST http://localhost:5051/api/evaluate \
  -F "assignment=@data/test_assignment.txt" \
  -F "notebook=@data/test_notebook.ipynb" \
  | jq '.breakdown'
```

**Expected output:**
```json
{
  "overall_score": 90,
  "breakdown": {
    "requirements_met": 13,
    "requirements_partial": 3,
    "requirements_missing": 1,
    "critical_failures": 0
  }
}
```

### Health Checks

```bash
# Backend health
curl http://localhost:5051/health

# ML service health (through backend)
curl http://localhost:5051/health | jq '.ml_service'
```

---

## ðŸ“ Project Structure

```
didyouevencode/
â”œâ”€â”€ frontend/                  # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main-page/        # Landing page component
â”‚   â”‚   â”œâ”€â”€ results/          # Results display component
â”‚   â”‚   â”œâ”€â”€ assets/           # Logo and images
â”‚   â”‚   â”œâ”€â”€ App.jsx           # Main app component
â”‚   â”‚   â”œâ”€â”€ config.js         # Environment config
â”‚   â”‚   â””â”€â”€ App.css           # Global styles
â”‚   â”œâ”€â”€ .env.example          # Frontend env template
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                   # Node.js API (MVC)
â”‚   â”œâ”€â”€ controllers/          # HTTP request handlers
â”‚   â”‚   â””â”€â”€ evaluation.controller.js
â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â”‚   â”œâ”€â”€ evaluation-service.js
â”‚   â”‚   â”œâ”€â”€ evidence-service.js
â”‚   â”‚   â”œâ”€â”€ scoring-service.js
â”‚   â”‚   â””â”€â”€ ml-service.js
â”‚   â”œâ”€â”€ routes/               # API route definitions
â”‚   â”œâ”€â”€ middleware/           # File upload, error handling
â”‚   â”œâ”€â”€ utils/                # Notebook parsing utilities
â”‚   â”œâ”€â”€ config/               # Configuration management
â”‚   â”œâ”€â”€ globals/              # Constants
â”‚   â”œâ”€â”€ .env.example          # Backend env template
â”‚   â””â”€â”€ server.js             # Entry point
â”‚
â”œâ”€â”€ colab/
â”‚   â””â”€â”€ ml_service.ipynb      # Python ML service
â”‚
â”œâ”€â”€ data/                     # Test files
â”‚   â”œâ”€â”€ test_assignment.txt
â”‚   â””â”€â”€ test_notebook.ipynb
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ colab-setup.md
â”‚
â””â”€â”€ README.md                 # This file
```

---

## ðŸ”§ Configuration

### Environment Variables

#### Backend (`backend/.env`)

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Backend server port | `5051` |
| `ML_SERVICE_URL` | Colab Cloudflare tunnel URL | **Required** |
| `UPLOAD_DIR` | Temporary file storage | `uploads/` |
| `REQUEST_TIMEOUT` | API timeout (milliseconds) | `300000` (5 min) |

#### Frontend (`frontend/.env`)

| Variable | Description | Default |
|----------|-------------|---------|
| `VITE_API_URL` | Backend API endpoint | `http://localhost:5051` |
| `VITE_REQUEST_TIMEOUT` | Request timeout (ms) | `300000` |

**Note:** Frontend variables must be prefixed with `VITE_` to be exposed by Vite bundler.

### Updating Colab URL

The Cloudflare tunnel URL changes each time you restart Colab (~12 hour sessions). Update it:

```bash
# Method 1: Edit .env file
nano backend/.env
# Change: ML_SERVICE_URL=https://new-url.trycloudflare.com

# Method 2: Environment variable
export ML_SERVICE_URL=https://new-url.trycloudflare.com
npm start
```

---

## ðŸŽ¯ How It Works

The evaluation pipeline executes in **6 stages**:

### Stage 1: Rubric Compilation
- **Method:** Template-based regex parsing
- **Input:** Assignment text file
- **Output:** List of requirements with weights
- **Time:** ~0.5s

### Stage 2: Chunk Extraction
- **Method:** Parse Jupyter notebook structure
- **Input:** `.ipynb` file
- **Process:**
    - Extract code cells and markdown
    - Split large cells (>40 lines) into 30-line chunks with 10-line overlap
- **Output:** 20-30 semantic code chunks
- **Time:** <0.1s

### Stage 3: Embedding Generation
- **Method:** MiniLM sentence transformer
- **Input:** Code chunks
- **Process:** Convert to 384-dimensional vectors
- **Hardware:** GPU-accelerated when available
- **Output:** Embeddings matrix [N Ã— 384]
- **Time:** 0.3-1s (GPU) / 1-2s (CPU)

### Stage 4: Vector Search
- **Method:** FAISS cosine similarity (IndexFlatIP)
- **Input:** Requirements + embeddings
- **Process:** Find top-3 most relevant chunks per requirement
- **Parallelization:** All 17 requirements processed simultaneously
- **Output:** 51 chunk matches (17 Ã— 3)
- **Time:** 2-3s

### Stage 5: Evidence Extraction
- **Method:** Rule-based pattern matching (no LLM - deterministic)
- **Input:** Requirement text + retrieved code chunks
- **Process:**
    - Keyword matching with stop-word filtering
    - Pattern detection (imports, function definitions, API calls)
    - Match ratio: â‰¥60% = PASS, â‰¥30% = PARTIAL, <60% = FAIL
- **Parallelization:** All requirements evaluated simultaneously
- **Output:** PASS/PARTIAL/FAIL + confidence score per requirement
- **Time:** 2-3s

### Stage 6: Report Generation
- **Method:** Flan-T5 text generation + score calculation
- **Input:** All evidence results + scores
- **Process:**
    - Generate natural language summary (1 LLM call)
    - Calculate overall score and breakdown
    - Format JSON report with evidence quotes
- **Hardware:** GPU-accelerated when available
- **Output:** Complete evaluation report with AI feedback
- **Time:** 2-5s (GPU) / 8-15s (CPU)

**Total Pipeline Time:** 5-15 seconds

---

## ðŸ§  Key Technical Decisions

### Why Rule-Based Evidence Extraction?

Initially used Flan-T5 for evidence extraction, but switched to rule-based for:
- âœ… **Speed:** 0.1s vs 5-50s per requirement
- âœ… **Reliability:** Deterministic, no hallucinations
- âœ… **Cost:** No GPU needed for this stage
- âœ… **Parallelization:** Can process 17 requirements simultaneously

**Trade-off:** Less nuanced understanding, but 95%+ accuracy for common patterns.

### Why FAISS?

- Efficient similarity search for large codebases
- GPU/CPU compatible
- Industry-standard (used by Facebook, OpenAI)
- ~10x faster than naive cosine similarity

### Why Cloudflare Tunnel?

- Free public URL for Colab (no ngrok limits)
- HTTPS by default
- No port forwarding needed
- Perfect for demos and hackathons

---

## ðŸš§ Known Limitations

1. **Colab URL resets** - Cloudflare tunnel URL changes when Colab restarts (~12 hours)
2. **Single notebook per evaluation** - No batch processing yet
3. **English only** - Assignment text and code comments should be in English
4. **Pattern-based matching** - May miss creative solutions that use unconventional approaches
5. **No authentication** - Open endpoints (fine for hackathon/demo)
6. **File size limits** - 10MB max per file

---

## ðŸ› Troubleshooting

### Backend won't start

```bash
# Check if port is in use
lsof -i :5051

# Try different port
PORT=5052 npm start
```

### Colab connection fails

```bash
# Check ML service URL in .env
cat backend/.env | grep ML_SERVICE_URL

# Test ML service directly
curl https://your-url.trycloudflare.com/health
```

### Evaluation times out

```bash
# Increase timeout in backend/.env
REQUEST_TIMEOUT=600000  # 10 minutes

# Or in frontend/.env
VITE_REQUEST_TIMEOUT=600000
```

### GPU not being used in Colab

1. Runtime â†’ Change runtime type
2. Select "T4 GPU"
3. Click Save
4. Re-run all cells

---

## ðŸ‘¤ Author

**Aleksei Shapovalov**  
Group 190 | CS Hackathon 2026

- Email: aleksei.a.shapovalov@gmail.com
- GitHub: [@aashapovalov](https://github.com/aashapovalov)
---


