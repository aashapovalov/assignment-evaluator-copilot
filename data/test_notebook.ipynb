{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\"# Text Summarization Assignment\\n\", \"## Part 1: Data Loading\"]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 1,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Load datasets\\n\",\n",
    "        \"train_df = pd.read_csv('train.csv')\\n\",\n",
    "        \"test_df = pd.read_csv('test.csv')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Sample 100 rows\\n\",\n",
    "        \"train_df = train_df.sample(100, random_state=42)\\n\",\n",
    "        \"test_df = test_df.sample(100, random_state=42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print('Train shape:', train_df.shape)\\n\",\n",
    "        \"print('Test shape:', test_df.shape)\\n\",\n",
    "        \"print('First 3 examples:')\\n\",\n",
    "        \"train_df.head(3)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\"## Part 2: Model Setup\"]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 2,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from transformers import T5ForConditionalGeneration, AutoTokenizer\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"\\n\",\n",
    "        \"model = T5ForConditionalGeneration.from_pretrained('t5-small')\\n\",\n",
    "        \"tokenizer = AutoTokenizer.from_pretrained('t5-small')\\n\",\n",
    "        \"\\n\",\n",
    "        \"device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
    "        \"model = model.to(device)\\n\",\n",
    "        \"model.eval()\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f'Model on {device}')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\"## Part 3: Summarization\"]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 3,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def summarize(text):\\n\",\n",
    "        \"    inputs = tokenizer('summarize: ' + text, return_tensors='pt', max_length=512, truncation=True)\\n\",\n",
    "        \"    inputs = inputs.to(device)\\n\",\n",
    "        \"    outputs = model.generate(**inputs, max_length=150)\\n\",\n",
    "        \"    return tokenizer.decode(outputs[0], skip_special_tokens=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Test on examples\\n\",\n",
    "        \"for i in range(5):\\n\",\n",
    "        \"    text = test_df.iloc[i]['text']\\n\",\n",
    "        \"    summary = summarize(text)\\n\",\n",
    "        \"    print(f'Summary {i+1}: {summary}')\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 4\n",
    "}"
   ],
   "id": "35cfeadf58758eec"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
